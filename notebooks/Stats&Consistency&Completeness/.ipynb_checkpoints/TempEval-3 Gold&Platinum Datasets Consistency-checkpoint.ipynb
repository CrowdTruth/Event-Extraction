{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotated events and time expressions\n",
    "goldevents = pd.read_csv(\"../../data/TempEval3-data/TE3-Gold_events.csv\", skip_blank_lines=True)\n",
    "platinumevents = pd.read_csv(\"../../data/TempEval3-data/TE3-Platinum_events.csv\", skip_blank_lines=True)\n",
    "goldtime = pd.read_csv(\"../../data/TempEval3-data/TE3-Gold_time.csv\", skip_blank_lines=True)\n",
    "platinumtime = pd.read_csv(\"../../data/TempEval3-data/TE3-Platinum_time.csv\", skip_blank_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens in the dataset\n",
    "goldtokens = pd.read_csv(\"../../data/TempEval3-data/TE3-Gold_tokens.csv\", skip_blank_lines=True)\n",
    "platinumtokens = pd.read_csv(\"../../data/TempEval3-data/TE3-Platinum_tokens.csv\", skip_blank_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve the intersection of two lists\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type consistency at the level of annotated tokens\n",
    "goldeventslist = list(goldevents[\"Token POS\"].str.split(' ', expand=True).stack().unique())\n",
    "platinumeventslist = list(platinumevents[\"Token POS\"].str.split(' ', expand=True).stack().unique())\n",
    "\n",
    "goldtimelist = list(goldtime[\"Token POS\"].str.split(' ', expand=True).stack().unique())\n",
    "platinumtimelist = list(platinumtime[\"Token POS\"].str.split(' ', expand=True).stack().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at-IN', 'coming-VB', 'election-NN', 'end-NN', 'flat-JJ', 'following-VB', 'good-JJ', 'half-NN', 'in-IN', 'march-NN', 'part-NN', 'trading-NN', 'up-RB']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(goldeventslist, goldtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at-IN', 'end-NN', 'following-VB', 'tenure-NN']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(goldeventslist, platinumtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end-NN', 'time-NN', '90-CD', '40-CD', 'good-JJ']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(platinumeventslist, goldtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season-NN', 'end-NN', 'time-NN', '90-CD']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(platinumeventslist, platinumtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type consistency at the level of annotated lemmas\n",
    "goldeventslist = list(goldevents[\"Lemma POS\"].str.split(' ', expand=True).stack().unique())\n",
    "platinumeventslist = list(platinumevents[\"Lemma POS\"].str.split(' ', expand=True).stack().unique())\n",
    "\n",
    "goldtimelist = list(goldtime[\"Lemma POS\"].str.split(' ', expand=True).stack().unique())\n",
    "platinumtimelist = list(platinumtime[\"Lemma POS\"].str.split(' ', expand=True).stack().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at-IN', 'beginning-NN', 'come-VB', 'election-NN', 'end-NN', 'flat-JJ', 'follow-VB', 'good-JJ', 'half-NN', 'in-IN', 'march-NN', 'part-NN', 'period-NN', 'trading-NN', 'up-RB']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(goldeventslist, goldtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at-IN', 'end-NN', 'follow-VB', 'tenure-NN']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(goldeventslist, platinumtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end-NN', 'come-VB', 'time-NN', '90-CD', '40-CD', 'good-JJ']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(platinumeventslist, goldtimelist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season-NN', 'end-NN', 'time-NN', '90-CD']\n"
     ]
    }
   ],
   "source": [
    "print(intersection(platinumeventslist, platinumtimelist)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there are tokens or lemmas that are annotated as events in one dataset but not in other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_event_tokens = list(set(platinumevents[\"Token POS\"]))\n",
    "g_event_tokens = list(set(goldevents[\"Token POS\"]))\n",
    "p_event_lemmas = list(set(platinumevents[\"Lemma POS\"]))\n",
    "g_event_lemmas = list(set(goldevents[\"Lemma POS\"]))\n",
    "\n",
    "p_time_tokens = list(set(platinumtime[\"Token POS\"]))\n",
    "g_time_tokens = list(set(goldtime[\"Token POS\"]))\n",
    "p_time_lemmas = list(set(platinumtime[\"Lemma POS\"]))\n",
    "g_time_lemmas = list(set(goldtime[\"Lemma POS\"]))\n",
    "\n",
    "p_time_tokens_single = filter(lambda x: ' ' not in x, p_time_tokens)\n",
    "g_time_tokens_single = filter(lambda x: ' ' not in x, g_time_tokens)\n",
    "p_time_lemmas_single = filter(lambda x: ' ' not in x, p_time_lemmas)\n",
    "g_time_lemmas_single = filter(lambda x: ' ' not in x, g_time_lemmas)\n",
    "        \n",
    "p_time_tokens_multi = filter(lambda x: ' ' in x, p_time_tokens)\n",
    "g_time_tokens_multi = filter(lambda x: ' ' in x, g_time_tokens)\n",
    "p_time_lemmas_multi = filter(lambda x: ' ' in x, p_time_lemmas)\n",
    "g_time_lemmas_multi = filter(lambda x: ' ' in x, g_time_lemmas)\n",
    "\n",
    "# unique tokens\n",
    "p_tokens = list(set(platinumtokens[\"Token POS\"]))\n",
    "g_tokens = list(set(goldtokens[\"Token POS\"]))\n",
    "p_lemmas = list(set(platinumtokens[\"Lemma POS\"]))\n",
    "g_lemmas = list(set(goldtokens[\"Lemma POS\"]))\n",
    "\n",
    "# all tokens\n",
    "all_p_tokens = list(platinumtokens[\"Token POS\"])\n",
    "all_g_tokens = list(goldtokens[\"Token POS\"])\n",
    "all_p_lemmas = list(platinumtokens[\"Lemma POS\"])\n",
    "all_g_lemmas = list(goldtokens[\"Lemma POS\"])\n",
    "\n",
    "# all tokens that are not times\n",
    "all_p_tokens_not_marked = list(platinumtokens[platinumtokens[\"Is Time Expression\"] == 0][\"Token POS\"])\n",
    "all_g_tokens_not_marked = list(goldtokens[goldtokens[\"Is Time Expression\"] == 0][\"Token POS\"])\n",
    "all_p_lemmas_not_marked = list(platinumtokens[platinumtokens[\"Is Time Expression\"] == 0][\"Lemma POS\"])\n",
    "all_g_lemmas_not_marked = list(goldtokens[goldtokens[\"Is Time Expression\"] == 0][\"Lemma POS\"])\n",
    "\n",
    "unique_p_tokens_not_marked = list(set(platinumtokens[platinumtokens[\"Is Time Expression\"] == 0][\"Token POS\"]))\n",
    "unique_g_tokens_not_marked = list(set(goldtokens[goldtokens[\"Is Time Expression\"] == 0][\"Token POS\"]))\n",
    "unique_p_lemmas_not_marked = list(set(platinumtokens[platinumtokens[\"Is Time Expression\"] == 0][\"Lemma POS\"]))\n",
    "unique_g_lemmas_not_marked = list(set(goldtokens[goldtokens[\"Is Time Expression\"] == 0][\"Lemma POS\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff(first, second):\n",
    "    second = set(second)\n",
    "    return [item for item in first if item not in second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tokens_in_p_not_in_g = diff(p_event_tokens, g_event_tokens)\n",
    "event_tokens_in_g_not_in_p = diff(g_event_tokens, p_event_tokens)\n",
    "event_lemmas_in_p_not_in_g = diff(p_event_lemmas, g_event_lemmas)\n",
    "event_lemmas_in_g_not_in_p = diff(g_event_lemmas, p_event_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "188\n"
     ]
    }
   ],
   "source": [
    "event_tokens_in_p_not_in_g_events_but_in_g_tokens = intersection(event_tokens_in_p_not_in_g, g_tokens)\n",
    "print(len(event_tokens_in_p_not_in_g_events_but_in_g_tokens))\n",
    "total_occ = len([i for i in all_g_tokens if i in event_tokens_in_p_not_in_g_events_but_in_g_tokens ])\n",
    "print(total_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "event_lemmas_in_p_not_in_g_events_but_in_g_lemmas = intersection(event_lemmas_in_p_not_in_g, g_lemmas)\n",
    "print(len(event_lemmas_in_p_not_in_g_events_but_in_g_lemmas))\n",
    "total_occ = len([i for i in all_g_lemmas if i in event_lemmas_in_p_not_in_g_events_but_in_g_lemmas ])\n",
    "print(total_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "678\n"
     ]
    }
   ],
   "source": [
    "event_tokens_in_g_not_in_p_events_but_in_p_tokens = intersection(event_tokens_in_g_not_in_p, p_tokens)\n",
    "print(len(event_tokens_in_g_not_in_p_events_but_in_p_tokens))\n",
    "total_occ = len([i for i in all_p_tokens if i in event_tokens_in_g_not_in_p_events_but_in_p_tokens ])\n",
    "print(total_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "552\n"
     ]
    }
   ],
   "source": [
    "event_lemmas_in_g_not_in_p_events_but_in_p_lemmas = intersection(event_lemmas_in_g_not_in_p, p_lemmas)\n",
    "print(len(event_lemmas_in_g_not_in_p_events_but_in_p_lemmas))\n",
    "total_occ = len([i for i in all_p_lemmas if i in event_lemmas_in_g_not_in_p_events_but_in_p_lemmas ])\n",
    "print(total_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tokens_in_p_not_in_g = diff(p_time_tokens_single, g_time_tokens_single)\n",
    "time_tokens_in_g_not_in_p = diff(g_time_tokens_single, p_time_tokens_single)\n",
    "time_lemmas_in_p_not_in_g = diff(p_time_lemmas_single, g_time_lemmas_single)\n",
    "time_lemmas_in_g_not_in_p = diff(g_time_lemmas_single, p_time_lemmas_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "41\n",
      "['tenure-NN', 'minutes-NN', '12-CD', '58-CD']\n"
     ]
    }
   ],
   "source": [
    "time_tokens_in_p_not_in_g_time_but_in_g_tokens = intersection(time_tokens_in_p_not_in_g, unique_g_tokens_not_marked)\n",
    "print(len(time_tokens_in_p_not_in_g_time_but_in_g_tokens))\n",
    "total_occ = len([i for i in all_g_tokens_not_marked if i in time_tokens_in_p_not_in_g_time_but_in_g_tokens ])\n",
    "print(total_occ)\n",
    "print(time_tokens_in_p_not_in_g_time_but_in_g_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "40\n",
      "['tenure-NN', '12-CD', '58-CD', 'minute-NN']\n"
     ]
    }
   ],
   "source": [
    "time_lemmas_in_p_not_in_g_time_but_in_g_lemmas = intersection(time_lemmas_in_p_not_in_g, unique_g_lemmas_not_marked)\n",
    "print(len(time_lemmas_in_p_not_in_g_time_but_in_g_lemmas))\n",
    "total_occ = len([i for i in all_g_lemmas_not_marked if i in time_lemmas_in_p_not_in_g_time_but_in_g_lemmas ])\n",
    "print(total_occ)\n",
    "print(time_lemmas_in_p_not_in_g_time_but_in_g_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "29\n",
      "['already-RB', 'current-JJ', 'months-NN', 'previously-RB', 'day-NN', 'summer-NN', 'second-JJ', 'recently-RB', 'then-RB', 'two-CD', 'yet-RB', 'soon-RB', 'last-JJ']\n"
     ]
    }
   ],
   "source": [
    "time_tokens_in_g_not_in_p_time_but_in_p_tokens = intersection(time_tokens_in_g_not_in_p, unique_p_tokens_not_marked)\n",
    "print(len(time_tokens_in_g_not_in_p_time_but_in_p_tokens))\n",
    "total_occ = len([i for i in all_p_tokens_not_marked if i in time_tokens_in_g_not_in_p_time_but_in_p_tokens ])\n",
    "print(total_occ)\n",
    "print(time_tokens_in_g_not_in_p_time_but_in_p_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "28\n",
      "['already-RB', 'current-JJ', 'previously-RB', 'summer-NN', 'second-JJ', 'recently-RB', 'then-RB', 'two-CD', 'yet-RB', 'soon-RB', 'last-JJ', 'month-NN']\n"
     ]
    }
   ],
   "source": [
    "time_lemmas_in_g_not_in_p_time_but_in_p_lemmas = intersection(time_lemmas_in_g_not_in_p, unique_p_lemmas_not_marked)\n",
    "print(len(time_lemmas_in_g_not_in_p_time_but_in_p_lemmas))\n",
    "total_occ = len([i for i in all_p_lemmas_not_marked if i in time_lemmas_in_g_not_in_p_time_but_in_p_lemmas ])\n",
    "print(total_occ)\n",
    "print(time_lemmas_in_g_not_in_p_time_but_in_p_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tokens_in_p_not_in_g = diff(p_time_tokens_multi, g_time_tokens_multi)\n",
    "time_tokens_in_g_not_in_p = diff(g_time_tokens_multi, p_time_tokens_multi)\n",
    "time_lemmas_in_p_not_in_g = diff(p_time_lemmas_multi, g_time_lemmas_multi)\n",
    "time_lemmas_in_g_not_in_p = diff(g_time_lemmas_multi, p_time_lemmas_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goldtokens = pd.read_csv(\"../TempEval3-data/TBAQ-cleaned_tokens.csv\", skip_blank_lines=True)\n",
    "platinumtokens = pd.read_csv(\"../TempEval3-data/TE3-Platinum_tokens.csv\", skip_blank_lines=True)\n",
    "\n",
    "goldtokens_not_marked = goldtokens[goldtokens[\"Is Time Expression\"] == 0]\n",
    "platinumtokens_not_marked = platinumtokens[platinumtokens[\"Is Time Expression\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from itertools import izip as zip\n",
    "except ImportError: # will be 3.x series\n",
    "    pass\n",
    "from itertools import product\n",
    "\n",
    "def find_continuous_items(data):\n",
    "    for p in product(*data):\n",
    "        if all(b-a==1 for a, b in zip(p, p[1:])):\n",
    "            yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at-IN the-DT time-NN\n",
      "an-DT hour-NN\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "distinct = 0\n",
    "total = 0\n",
    "\n",
    "for item in time_tokens_in_p_not_in_g:\n",
    "    \n",
    "    elems = item.split(\" \")\n",
    "    no_elem = len(elems)\n",
    "    \n",
    "    \n",
    "    indexes = []\n",
    "    \n",
    "    for elem in elems:\n",
    "        elem = elem.split(\"-\")\n",
    "        indexes.append(goldtokens_not_marked.index[goldtokens_not_marked['Lowercase Token'] == elem[0]].tolist())\n",
    "         \n",
    "    #print(indexes) \n",
    "    \n",
    "    occurrences = list(find_continuous_items(indexes))\n",
    "    \n",
    "    if len(occurrences) != 0:\n",
    "        distinct = distinct + 1\n",
    "        print(item)\n",
    "    \n",
    "    total = total + len(occurrences)\n",
    "    \n",
    "print(distinct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the-DT time-NN\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "distinct = 0\n",
    "total = 0\n",
    "\n",
    "for item in time_tokens_in_g_not_in_p:\n",
    "    \n",
    "    elems = item.split(\" \")\n",
    "    no_elem = len(elems)\n",
    "    \n",
    "    \n",
    "    indexes = []\n",
    "    \n",
    "    for elem in elems:\n",
    "        elem = elem.split(\"-\")\n",
    "        indexes.append(platinumtokens_not_marked.index[platinumtokens_not_marked['Lowercase Token'] == elem[0]].tolist())\n",
    "         \n",
    "    #print(indexes) \n",
    "    \n",
    "    occurrences = list(find_continuous_items(indexes))\n",
    "    \n",
    "    if len(occurrences) != 0:\n",
    "        distinct = distinct + 1\n",
    "        print(item)\n",
    "    \n",
    "    total = total + len(occurrences)\n",
    "    \n",
    "print(distinct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at-IN the-DT time-NN\n",
      "a-DT hour-NN\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "distinct = 0\n",
    "total = 0\n",
    "\n",
    "for item in time_lemmas_in_p_not_in_g:\n",
    "\n",
    "    elems = item.split(\" \")\n",
    "    no_elem = len(elems)\n",
    "    \n",
    "    \n",
    "    indexes = []\n",
    "    \n",
    "    for elem in elems:\n",
    "        elem = elem.split(\"-\")\n",
    "        indexes.append(goldtokens_not_marked.index[goldtokens_not_marked['Lowercase Lemma Stanford'] == elem[0]].tolist())\n",
    "         \n",
    "    #print(indexes) \n",
    "    \n",
    "    occurrences = list(find_continuous_items(indexes))\n",
    "    \n",
    "    if len(occurrences) != 0:\n",
    "        distinct = distinct + 1\n",
    "        print(item)\n",
    "    \n",
    "    total = total + len(occurrences)\n",
    "    \n",
    "print(distinct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the-DT time-NN\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "distinct = 0\n",
    "total = 0\n",
    "\n",
    "for item in time_lemmas_in_g_not_in_p:\n",
    "\n",
    "    elems = item.split(\" \")\n",
    "    no_elem = len(elems)\n",
    "    \n",
    "    \n",
    "    indexes = []\n",
    "    \n",
    "    for elem in elems:\n",
    "        elem = elem.split(\"-\")\n",
    "        indexes.append(platinumtokens_not_marked.index[platinumtokens_not_marked['Lowercase Lemma Stanford'] == elem[0]].tolist())\n",
    "         \n",
    "    #print(indexes) \n",
    "    \n",
    "    occurrences = list(find_continuous_items(indexes))\n",
    "    \n",
    "    if len(occurrences) != 0:\n",
    "        distinct = distinct + 1\n",
    "        print(item)\n",
    "    \n",
    "    total = total + len(occurrences)\n",
    "    \n",
    "print(distinct)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
